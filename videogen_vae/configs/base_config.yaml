# Video Generation VAE Configuration

project:
  name: "videogen_vae"
  seed: 42
  output_dir: "./outputs"
  log_dir: "./logs"
  checkpoint_dir: "./checkpoints"
  
model:
  architecture: "dit"  # Use full DiT architecture for better quality

  # Optimized model dimensions for 2x24GB GPUs
  dim: 384           # Increased for better quality
  dim_mults: [1, 2, 4]  # Full complexity
  num_heads: 8
  head_dim: 64
  depth: 12          # Increased depth for better quality

  # Video parameters
  num_frames: 16     # Increased for better temporal modeling
  frame_size: 256    # Reduced for memory efficiency
  channels: 3
  patch_size: 8      # Smaller patches for better detail
  mlp_ratio: 4.0
  dropout: 0.1
  learn_sigma: true  # Enable for better quality

  # Diffusion parameters
  timesteps: 1000
  loss_type: "l2"
  beta_schedule: "cosine"

  # Conditioning
  use_text_conditioning: false  # Disabled for single-activity dataset
  text_encoder: "clip"  # Options: "clip", "t5", "llama"

  # Optimization
  gradient_checkpointing: true
  use_flash_attention: true  # Enable for better performance

data:
  dataset_path: "../../dataset/dataset_mp4_cleaned_simple"
  batch_size: 4  # Increased for 2x24GB GPUs
  num_workers: 4  # Increased for faster data loading

  # Video specifications
  fps: 24
  duration: 1  # seconds
  resolution: 256  # Match model frame_size

  # Data augmentation
  random_flip: true   # Re-enable for better training
  color_jitter: true  # Enable for better generalization

  # Caching
  cache_latents: true   # Re-enable caching for faster loading
  cache_dir: "./cache"

training:
  # Optimization
  optimizer: "adamw"
  learning_rate: 2e-4  # Slightly higher for faster convergence
  weight_decay: 0.01
  gradient_clip_val: 1.0

  # Scheduler
  scheduler: "cosine"
  warmup_steps: 500  # Reduced for smaller dataset

  # Training duration
  num_epochs: 100  # More epochs for overfitting on small dataset
  save_every_n_epochs: 5
  validate_every_n_epochs: 3

  # Mixed precision
  mixed_precision: "bf16"  # Options: "no", "fp16", "bf16"

  # Multi-GPU
  distributed: true
  num_gpus: 2
  strategy: "ddp"  # Options: "ddp", "deepspeed", "fsdp"

  # Memory optimization
  gradient_accumulation_steps: 2  # Reduced for better gradient flow
  enable_xformers: true  # Enable for better performance
  cpu_offload: false
  pin_memory: true

  # Logging
  log_every_n_steps: 5  # More frequent logging for small dataset
  use_wandb: true
  wandb_project: "videogen_vae"
  
inference:
  num_inference_steps: 50
  guidance_scale: 7.5
  fps: 24
  
  # Memory optimization
  use_fp16: true
  enable_tiling: true
  
  # Output
  output_format: "mp4"
  codec: "h264"
  
# Hardware specific optimizations
hardware:
  device: "cuda"
  num_gpus: 2
  gpu_memory: 24  # GB per GPU
  
  # A40/3090 specific optimizations
  enable_tf32: true
  cudnn_benchmark: true 